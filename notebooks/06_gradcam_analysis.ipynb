{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqXCNU-XHCUQ",
        "outputId": "0a2e3949-56cf-45f9-b776-830cf55012d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2ia_496INTJ",
        "outputId": "9ea54ce9-6cfb-4988-a87b-ac6cd5427afe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/drive -name \"*.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7tumPHQIQ2t",
        "outputId": "1e774ffa-03f3-4e17-8606-2f124f11c20f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/oa_checkpoints/best_densenet121_res320.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CKPT_PATH = \"/content/drive/MyDrive/oa_checkpoints/best_densenet121_res320.pth\""
      ],
      "metadata": {
        "id": "1IAJquagI0XT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Exists:\", os.path.isfile(CKPT_PATH), CKPT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BjNYyzeIv8u",
        "outputId": "28348857-473b-46ca-ef3f-4e1d2acabd0d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists: True /content/drive/MyDrive/oa_checkpoints/best_densenet121_res320.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set dataset paths + create output folder\n",
        "DATASET_NAME = \"knee-osteoarthritis-dataset-with-severity\"\n",
        "DATA_DIR  = f\"/content/{DATASET_NAME}\"\n",
        "TRAIN_DIR = f\"{DATA_DIR}/train\"\n",
        "VAL_DIR   = f\"{DATA_DIR}/val\"\n",
        "TEST_DIR  = f\"{DATA_DIR}/test\"\n",
        "\n",
        "# If dataset folder missing, unzip again from Drive:\n",
        "ZIP_NAME = \"knee_oa_dataset.zip\"  # must match your zip name in Drive\n",
        "if not os.path.isdir(DATA_DIR):\n",
        "    print(\"Dataset not found. Unzipping from Drive...\")\n",
        "    zip_path = f\"/content/drive/MyDrive/{ZIP_NAME}\"\n",
        "    !unzip -q \"{zip_path}\" -d /content/\n",
        "print(\"Dataset ready ✅\")\n",
        "\n",
        "OUT_DIR = \"/content/drive/MyDrive/oa_checkpoints/gradcam_figures\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"TEST_DIR:\", TEST_DIR)\n",
        "print(\"OUT_DIR:\", OUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnGDw26DI4mb",
        "outputId": "63399f06-3e57-4538-9669-8d187b3ddddd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset not found. Unzipping from Drive...\n",
            "Dataset ready ✅\n",
            "TEST_DIR: /content/knee-osteoarthritis-dataset-with-severity/test\n",
            "OUT_DIR: /content/drive/MyDrive/oa_checkpoints/gradcam_figures\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model + loaders + Grad-CAM implementation (DenseNet)\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Use the SAME resolution as the checkpoint training\n",
        "IMAGE_SIZE = 320\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_ds = datasets.ImageFolder(TEST_DIR, transform=test_tfms)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "NUM_CLASSES = len(test_ds.classes)\n",
        "print(\"Classes:\", test_ds.classes, \"NUM_CLASSES:\", NUM_CLASSES)\n",
        "\n",
        "def build_densenet121(num_classes):\n",
        "    m = models.densenet121(weights=None)  # weights not needed because we load our checkpoint\n",
        "    in_features = m.classifier.in_features\n",
        "    m.classifier = nn.Linear(in_features, num_classes)\n",
        "    return m\n",
        "\n",
        "model = build_densenet121(NUM_CLASSES).to(device)\n",
        "model.load_state_dict(torch.load(CKPT_PATH, map_location=device))\n",
        "model.eval()\n",
        "print(\"Loaded model ✅\")\n",
        "\n",
        "# --- utilities for visualization ---\n",
        "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
        "IMAGENET_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
        "\n",
        "def denorm_img(t_chw):\n",
        "    x = t_chw.detach().cpu().numpy().transpose(1,2,0)\n",
        "    x = (x * IMAGENET_STD) + IMAGENET_MEAN\n",
        "    return np.clip(x, 0, 1)\n",
        "\n",
        "def overlay_heatmap_on_image(img_hwc, heatmap_hw, alpha=0.35):\n",
        "    heatmap = plt.get_cmap(\"jet\")(heatmap_hw)[..., :3]\n",
        "    overlay = (1 - alpha) * img_hwc + alpha * heatmap\n",
        "    return np.clip(overlay, 0, 1)\n",
        "\n",
        "class GradCAM:\n",
        "    def __init__(self, model, target_module):\n",
        "        self.model = model\n",
        "        self.target_module = target_module\n",
        "        self.activations = None\n",
        "        self.gradients = None\n",
        "\n",
        "        self.fwd_hook = target_module.register_forward_hook(self._forward_hook)\n",
        "        self.bwd_hook = target_module.register_full_backward_hook(self._backward_hook)\n",
        "\n",
        "    def _forward_hook(self, module, inp, out):\n",
        "        self.activations = out\n",
        "\n",
        "    def _backward_hook(self, module, grad_in, grad_out):\n",
        "        self.gradients = grad_out[0]\n",
        "\n",
        "    def remove(self):\n",
        "        self.fwd_hook.remove()\n",
        "        self.bwd_hook.remove()\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalize(cam):\n",
        "        cam = cam - cam.min()\n",
        "        cam = cam / (cam.max() + 1e-8)\n",
        "        return cam\n",
        "\n",
        "    def __call__(self, x, class_idx=None):\n",
        "        \"\"\"\n",
        "        x: [1,3,H,W]\n",
        "        returns: cam [H,W] 0..1, pred_idx, probs numpy\n",
        "        \"\"\"\n",
        "        self.model.zero_grad(set_to_none=True)\n",
        "        logits = self.model(x)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        pred_idx = int(torch.argmax(probs, dim=1).item())\n",
        "\n",
        "        if class_idx is None:\n",
        "            class_idx = pred_idx\n",
        "\n",
        "        score = logits[0, class_idx]\n",
        "        self.model.zero_grad(set_to_none=True)\n",
        "        score.backward(retain_graph=False)\n",
        "\n",
        "        grads = self.gradients              # [1,C,h,w]\n",
        "        acts  = self.activations            # [1,C,h,w]\n",
        "        weights = grads.mean(dim=(2,3), keepdim=True)  # [1,C,1,1]\n",
        "        cam = (weights * acts).sum(dim=1, keepdim=True)\n",
        "        cam = F.relu(cam)\n",
        "\n",
        "        cam = F.interpolate(cam, size=x.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "        cam = cam[0,0].detach().cpu().numpy()\n",
        "        cam = self._normalize(cam)\n",
        "\n",
        "        return cam, pred_idx, probs[0].detach().cpu().numpy()\n",
        "\n",
        "# Good DenseNet target layer\n",
        "target_layer = model.features.denseblock4\n",
        "gradcam = GradCAM(model, target_layer)\n",
        "print(\"Grad-CAM ready ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx5cDSzSJEyg",
        "outputId": "767097e4-46c8-4648-9c66-84f9e4da222f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Classes: ['0', '1', '2', '3', '4'] NUM_CLASSES: 5\n",
            "Loaded model ✅\n",
            "Grad-CAM ready ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick correct/wrong samples, save overlays + summary grid\n",
        "import os\n",
        "from math import ceil\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# 1) Run predictions over test set (cache images)\n",
        "all_preds, all_targets, cached_imgs = [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, targets in test_loader:\n",
        "        out = model(imgs.to(device))\n",
        "        preds = out.argmax(dim=1).detach().cpu().numpy().tolist()\n",
        "        all_preds.extend(preds)\n",
        "        all_targets.extend(targets.numpy().tolist())\n",
        "        cached_imgs.extend([t.detach().cpu() for t in imgs])  # normalized tensors\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_targets = np.array(all_targets)\n",
        "\n",
        "test_acc = (all_preds == all_targets).mean()\n",
        "test_macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "print(\"Checkpoint TEST acc:\", test_acc)\n",
        "print(\"Checkpoint TEST macro-F1:\", test_macro_f1)\n",
        "\n",
        "# 2) Choose examples (6 correct + 6 wrong)\n",
        "correct_idx = np.where(all_preds == all_targets)[0]\n",
        "wrong_idx   = np.where(all_preds != all_targets)[0]\n",
        "\n",
        "np.random.seed(42)\n",
        "N_CORRECT = 6\n",
        "N_WRONG = 6\n",
        "\n",
        "picked_correct = np.random.choice(correct_idx, size=min(N_CORRECT, len(correct_idx)), replace=False)\n",
        "picked_wrong   = np.random.choice(wrong_idx,   size=min(N_WRONG,   len(wrong_idx)),   replace=False)\n",
        "\n",
        "picked = [(\"correct\", int(i)) for i in picked_correct] + [(\"wrong\", int(i)) for i in picked_wrong]\n",
        "print(\"Picked:\", len(picked), \"examples\")\n",
        "\n",
        "def save_cam_example(tag, i, use_true_class=False):\n",
        "    x = cached_imgs[i].unsqueeze(0).to(device)\n",
        "    true_y = int(all_targets[i])\n",
        "    pred_y = int(all_preds[i])\n",
        "\n",
        "    class_for_cam = true_y if use_true_class else pred_y\n",
        "    cam, _, _ = gradcam(x, class_idx=class_for_cam)\n",
        "\n",
        "    img = denorm_img(cached_imgs[i])\n",
        "    overlay = overlay_heatmap_on_image(img, cam, alpha=0.35)\n",
        "\n",
        "    plt.figure(figsize=(9,3))\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(img); plt.axis(\"off\")\n",
        "    plt.title(f\"Original\\nTrue={true_y}, Pred={pred_y}\")\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(cam, cmap=\"jet\"); plt.axis(\"off\")\n",
        "    plt.title(\"CAM (true)\" if use_true_class else \"CAM (pred)\")\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(overlay); plt.axis(\"off\")\n",
        "    plt.title(\"Overlay\")\n",
        "\n",
        "    out_name = f\"{tag}_idx{i}_T{true_y}_P{pred_y}_{'truecam' if use_true_class else 'predcam'}.png\"\n",
        "    out_path = os.path.join(OUT_DIR, out_name)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=220)\n",
        "    plt.close()\n",
        "    return out_path\n",
        "\n",
        "saved = []\n",
        "for tag, i in picked:\n",
        "    saved.append(save_cam_example(tag, i, use_true_class=False))\n",
        "    if tag == \"wrong\":\n",
        "        saved.append(save_cam_example(tag, i, use_true_class=True))\n",
        "\n",
        "print(\"Saved images:\", len(saved))\n",
        "\n",
        "# 3) Summary grid (pred-cam overlays only)\n",
        "grid_items = []\n",
        "for tag, i in picked:\n",
        "    x = cached_imgs[i].unsqueeze(0).to(device)\n",
        "    true_y = int(all_targets[i]); pred_y = int(all_preds[i])\n",
        "    cam, _, _ = gradcam(x, class_idx=pred_y)\n",
        "    img = denorm_img(cached_imgs[i])\n",
        "    overlay = overlay_heatmap_on_image(img, cam, alpha=0.35)\n",
        "    grid_items.append((tag, i, true_y, pred_y, overlay))\n",
        "\n",
        "cols = 4\n",
        "rows = ceil(len(grid_items) / cols)\n",
        "plt.figure(figsize=(4*cols, 4*rows))\n",
        "for k, (tag, i, t, p, overlay) in enumerate(grid_items, start=1):\n",
        "    plt.subplot(rows, cols, k)\n",
        "    plt.imshow(overlay)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"{tag} | T={t} P={p}\")\n",
        "plt.tight_layout()\n",
        "\n",
        "grid_path = os.path.join(OUT_DIR, \"gradcam_summary_grid.png\")\n",
        "plt.savefig(grid_path, dpi=240)\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved summary grid ✅:\", grid_path)\n",
        "print(\"Open folder:\", OUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1Xv2ftOJKNs",
        "outputId": "50b4bf27-626c-4663-fc9a-2d1a010e0168"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint TEST acc: 0.6183574879227053\n",
            "Checkpoint TEST macro-F1: 0.6623441983437284\n",
            "Picked: 12 examples\n",
            "Saved images: 18\n",
            "Saved summary grid ✅: /content/drive/MyDrive/oa_checkpoints/gradcam_figures/gradcam_summary_grid.png\n",
            "Open folder: /content/drive/MyDrive/oa_checkpoints/gradcam_figures\n"
          ]
        }
      ]
    }
  ]
}