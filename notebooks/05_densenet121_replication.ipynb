{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzETZmxki_hB",
        "outputId": "b28488db-69b1-4052-8719-34812c553cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset not found. Mounting Drive...\n",
            "Mounted at /content/drive\n",
            "Unzipping dataset...\n",
            "Dataset ready ✅\n",
            "['.config', 'drive', 'knee-osteoarthritis-dataset-with-severity', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# AUTO DATASET LOADER + DenseNet121 Replication\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "\n",
        "DATASET_NAME = \"knee-osteoarthritis-dataset-with-severity\"\n",
        "ZIP_NAME = \"knee_oa_dataset.zip\"   # make sure this matches your Drive\n",
        "\n",
        "if not os.path.isdir(f\"/content/{DATASET_NAME}\"):\n",
        "    print(\"Dataset not found. Mounting Drive...\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    zip_path = f\"/content/drive/MyDrive/{ZIP_NAME}\"\n",
        "    if not os.path.isfile(zip_path):\n",
        "        raise FileNotFoundError(f\"ZIP file not found at {zip_path}\")\n",
        "\n",
        "    print(\"Unzipping dataset...\")\n",
        "    !unzip -q \"{zip_path}\" -d /content/\n",
        "\n",
        "print(\"Dataset ready ✅\")\n",
        "print(os.listdir(\"/content\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, time, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULyBZwXpj1NP",
        "outputId": "674d6204-b06f-4d8a-ba48-4cccfecb86fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/knee-osteoarthritis-dataset-with-severity\"\n",
        "TRAIN_DIR = f\"{DATA_DIR}/train\"\n",
        "VAL_DIR   = f\"{DATA_DIR}/val\"\n",
        "TEST_DIR  = f\"{DATA_DIR}/test\"\n",
        "\n",
        "RUN_NAME = time.strftime(\"densenet121_replication_%Y%m%d_%H%M%S\")\n",
        "RUN_DIR = f\"/content/experiments/{RUN_NAME}\"\n",
        "os.makedirs(f\"{RUN_DIR}/checkpoints\", exist_ok=True)\n",
        "os.makedirs(f\"{RUN_DIR}/logs\", exist_ok=True)\n",
        "\n",
        "print(\"RUN_DIR:\", RUN_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayamFhfIj4RA",
        "outputId": "ed92a9e5-f726-4016-f734-933330e05eac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN_DIR: /content/experiments/densenet121_replication_20260216_173015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "6JwgRyaZj60Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(VAL_DIR, transform=val_tfms)\n",
        "test_ds  = datasets.ImageFolder(TEST_DIR, transform=val_tfms)\n",
        "\n",
        "NUM_CLASSES = len(train_ds.classes)\n",
        "print(\"Classes:\", train_ds.classes)\n",
        "\n",
        "# Weighted sampler (replicating imbalance handling from literature)\n",
        "labels = np.array([y for _, y in train_ds.samples])\n",
        "class_counts = np.bincount(labels, minlength=NUM_CLASSES)\n",
        "class_weights = 1.0 / (class_counts + 1e-6)\n",
        "sample_weights = torch.DoubleTensor(class_weights[labels])\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"Train class counts:\", class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfNc9pCQj9pM",
        "outputId": "a840e20a-2a4b-46ce-cdad-413b899949f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['0', '1', '2', '3', '4']\n",
            "Train class counts: [2286 1046 1516  757  173]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_densenet121(num_classes):\n",
        "    model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
        "    in_features = model.classifier.in_features\n",
        "    model.classifier = nn.Linear(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "model = build_densenet121(NUM_CLASSES).to(device)\n",
        "\n",
        "# Freeze backbone first\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\"DenseNet121 ready ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WOJf3W_j_7v",
        "outputId": "8dd31fc4-cbfa-40ee-e531-548cd3972c16"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 158MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DenseNet121 ready ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss (standard CE for replication baseline)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(\"Using CrossEntropyLoss ✅\")\n",
        "\n",
        "# Stage 1: train only classifier\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode=\"max\",\n",
        "    factor=0.5,\n",
        "    patience=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahpuq3OQkivq",
        "outputId": "cd226733-983f-4967-cbea-0a307afd65e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CrossEntropyLoss ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(model, loader, train=False):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    all_preds, all_targets = [], []\n",
        "\n",
        "    for imgs, targets in loader:\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(train):\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        all_preds.extend(preds.detach().cpu().numpy())\n",
        "        all_targets.extend(targets.detach().cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "    return avg_loss, acc, macro_f1"
      ],
      "metadata": {
        "id": "PCM8QF3TksXT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = []\n",
        "best_val_f1 = 0\n",
        "best_path = f\"{RUN_DIR}/checkpoints/best_densenet121.pth\"\n",
        "\n",
        "EPOCHS_STAGE1 = 3\n",
        "EPOCHS_STAGE2 = 17\n",
        "TOTAL_EPOCHS = EPOCHS_STAGE1 + EPOCHS_STAGE2\n",
        "\n",
        "print(\"Training plan:\", TOTAL_EPOCHS, \"epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS_STAGE1 + 1):\n",
        "\n",
        "    train_loss, train_acc, train_f1 = run_epoch(model, train_loader, train=True)\n",
        "    val_loss, val_acc, val_f1 = run_epoch(model, val_loader, train=False)\n",
        "\n",
        "    scheduler.step(val_f1)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"train loss {train_loss:.4f} acc {train_acc:.3f} f1 {train_f1:.3f} || \"\n",
        "          f\"val loss {val_loss:.4f} acc {val_acc:.3f} f1 {val_f1:.3f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), best_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsIfgIr8kvG5",
        "outputId": "768df736-2c3e-4292-d470-a86cb911ac1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training plan: 20 epochs\n",
            "Epoch 01 | train loss 1.5281 acc 0.305 f1 0.297 || val loss 1.4398 acc 0.317 f1 0.263\n",
            "Epoch 02 | train loss 1.3959 acc 0.375 f1 0.362 || val loss 1.3792 acc 0.361 f1 0.328\n",
            "Epoch 03 | train loss 1.3379 acc 0.407 f1 0.397 || val loss 1.4116 acc 0.306 f1 0.292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Stage 2: fine-tune last dense block + classifier --------\n",
        "\n",
        "# Unfreeze only: features.denseblock4 + features.norm5 + classifier\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = (\n",
        "        name.startswith(\"features.denseblock4\") or\n",
        "        name.startswith(\"features.norm5\") or\n",
        "        name.startswith(\"classifier\")\n",
        "    )\n",
        "\n",
        "# New optimizer for fine-tuning (smaller LR)\n",
        "optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=3e-4,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"max\", factor=0.5, patience=2\n",
        ")\n",
        "\n",
        "start_epoch = EPOCHS_STAGE1 + 1\n",
        "\n",
        "for epoch in range(start_epoch, TOTAL_EPOCHS + 1):\n",
        "    train_loss, train_acc, train_f1 = run_epoch(model, train_loader, train=True)\n",
        "    val_loss, val_acc, val_f1 = run_epoch(model, val_loader, train=False)\n",
        "\n",
        "    scheduler.step(val_f1)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"train loss {train_loss:.4f} acc {train_acc:.3f} f1 {train_f1:.3f} || \"\n",
        "          f\"val loss {val_loss:.4f} acc {val_acc:.3f} f1 {val_f1:.3f} | lr {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "\n",
        "print(\"Stage2 done ✅ Best val macro-F1:\", best_val_f1)\n",
        "print(\"Best checkpoint:\", best_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSfSbVKjmQw3",
        "outputId": "4535388a-efd4-4e27-a104-57cb2006d34f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 | train loss 1.0836 acc 0.508 f1 0.506 || val loss 1.0788 acc 0.538 f1 0.506 | lr 3.00e-04\n",
            "Epoch 05 | train loss 0.9063 acc 0.594 f1 0.585 || val loss 1.0832 acc 0.506 f1 0.534 | lr 3.00e-04\n",
            "Epoch 06 | train loss 0.8492 acc 0.618 f1 0.614 || val loss 1.0260 acc 0.513 f1 0.558 | lr 3.00e-04\n",
            "Epoch 07 | train loss 0.8124 acc 0.635 f1 0.631 || val loss 1.0976 acc 0.455 f1 0.541 | lr 3.00e-04\n",
            "Epoch 08 | train loss 0.7770 acc 0.651 f1 0.644 || val loss 1.0928 acc 0.552 f1 0.560 | lr 3.00e-04\n",
            "Epoch 09 | train loss 0.7527 acc 0.661 f1 0.661 || val loss 1.1758 acc 0.433 f1 0.506 | lr 3.00e-04\n",
            "Epoch 10 | train loss 0.7225 acc 0.687 f1 0.683 || val loss 0.9697 acc 0.584 f1 0.577 | lr 3.00e-04\n",
            "Epoch 11 | train loss 0.6961 acc 0.697 f1 0.694 || val loss 1.0069 acc 0.548 f1 0.560 | lr 3.00e-04\n",
            "Epoch 12 | train loss 0.7189 acc 0.681 f1 0.682 || val loss 1.0582 acc 0.525 f1 0.577 | lr 3.00e-04\n",
            "Epoch 13 | train loss 0.6695 acc 0.710 f1 0.708 || val loss 0.9858 acc 0.574 f1 0.576 | lr 1.50e-04\n",
            "Epoch 14 | train loss 0.6319 acc 0.733 f1 0.730 || val loss 0.9876 acc 0.553 f1 0.579 | lr 1.50e-04\n",
            "Epoch 15 | train loss 0.6211 acc 0.736 f1 0.734 || val loss 0.9789 acc 0.554 f1 0.560 | lr 1.50e-04\n",
            "Epoch 16 | train loss 0.6046 acc 0.746 f1 0.745 || val loss 1.0187 acc 0.539 f1 0.600 | lr 1.50e-04\n",
            "Epoch 17 | train loss 0.5877 acc 0.744 f1 0.742 || val loss 1.0344 acc 0.558 f1 0.592 | lr 1.50e-04\n",
            "Epoch 18 | train loss 0.5688 acc 0.759 f1 0.758 || val loss 1.0590 acc 0.528 f1 0.593 | lr 1.50e-04\n",
            "Epoch 19 | train loss 0.5708 acc 0.757 f1 0.756 || val loss 1.0646 acc 0.535 f1 0.589 | lr 7.50e-05\n",
            "Epoch 20 | train loss 0.5486 acc 0.765 f1 0.765 || val loss 1.0212 acc 0.550 f1 0.595 | lr 7.50e-05\n",
            "Stage2 done ✅ Best val macro-F1: 0.5995449411393963\n",
            "Best checkpoint: /content/experiments/densenet121_replication_20260216_173015/checkpoints/best_densenet121.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- TEST evaluation (best checkpoint) --------\n",
        "best_model = build_densenet121(NUM_CLASSES).to(device)\n",
        "best_model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "all_preds, all_targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, targets in test_loader:\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "        outputs = best_model(imgs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy().tolist())\n",
        "        all_targets.extend(targets.cpu().numpy().tolist())\n",
        "\n",
        "test_acc = accuracy_score(all_targets, all_preds)\n",
        "test_macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "print(\"TEST accuracy:\", test_acc)\n",
        "print(\"TEST macro-F1:\", test_macro_f1)\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(all_targets, all_preds, target_names=train_ds.classes, digits=4))\n",
        "\n",
        "cm = confusion_matrix(all_targets, all_preds)\n",
        "print(\"\\nConfusion matrix:\\n\", cm)\n",
        "\n",
        "# save metrics for your report\n",
        "metrics = {\n",
        "    \"best_val_macro_f1\": float(best_val_f1),\n",
        "    \"test_accuracy\": float(test_acc),\n",
        "    \"test_macro_f1\": float(test_macro_f1),\n",
        "    \"epochs_stage1\": EPOCHS_STAGE1,\n",
        "    \"epochs_stage2\": EPOCHS_STAGE2,\n",
        "    \"image_size\": IMAGE_SIZE,\n",
        "    \"batch_size\": BATCH_SIZE\n",
        "}\n",
        "\n",
        "with open(f\"{RUN_DIR}/logs/test_metrics.json\", \"w\") as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved:\", f\"{RUN_DIR}/logs/test_metrics.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8Ezvaizqwwt",
        "outputId": "7e1d78ef-0f63-445c-faed-665a4e87e022"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST accuracy: 0.538647342995169\n",
            "TEST macro-F1: 0.5855880938639025\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7282    0.5618    0.6343       639\n",
            "           1     0.2650    0.5068    0.3480       296\n",
            "           2     0.6044    0.4340    0.5052       447\n",
            "           3     0.6637    0.6726    0.6682       223\n",
            "           4     0.7800    0.7647    0.7723        51\n",
            "\n",
            "    accuracy                         0.5386      1656\n",
            "   macro avg     0.6083    0.5880    0.5856      1656\n",
            "weighted avg     0.6049    0.5386    0.5571      1656\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[359 230  46   4   0]\n",
            " [ 87 150  49  10   0]\n",
            " [ 43 159 194  51   0]\n",
            " [  4  27  31 150  11]\n",
            " [  0   0   1  11  39]]\n",
            "\n",
            "Saved: /content/experiments/densenet121_replication_20260216_173015/logs/test_metrics.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Improvement Experiment: deeper fine-tuning ----------\n",
        "# Load best checkpoint first (start from best weights)\n",
        "model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "\n",
        "# Unfreeze denseblock3 + denseblock4 + norm layers + classifier\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = (\n",
        "        name.startswith(\"features.denseblock3\") or\n",
        "        name.startswith(\"features.denseblock4\") or\n",
        "        name.startswith(\"features.norm5\") or\n",
        "        name.startswith(\"classifier\")\n",
        "    )\n",
        "\n",
        "# Lower LR for stability\n",
        "optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-4,           # LOWER than before\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"max\", factor=0.5, patience=2\n",
        ")\n",
        "\n",
        "# Run a short improvement fine-tune (5 epochs)\n",
        "IMPROVE_EPOCHS = 5\n",
        "best_val_f1_improve = best_val_f1\n",
        "best_path_improve = f\"{RUN_DIR}/checkpoints/best_densenet121_improved.pth\"\n",
        "\n",
        "for e in range(1, IMPROVE_EPOCHS + 1):\n",
        "    train_loss, train_acc, train_f1 = run_epoch(model, train_loader, train=True)\n",
        "    val_loss, val_acc, val_f1 = run_epoch(model, val_loader, train=False)\n",
        "\n",
        "    scheduler.step(val_f1)\n",
        "\n",
        "    print(f\"Improve {e:02d}/{IMPROVE_EPOCHS} | \"\n",
        "          f\"train loss {train_loss:.4f} acc {train_acc:.3f} f1 {train_f1:.3f} || \"\n",
        "          f\"val loss {val_loss:.4f} acc {val_acc:.3f} f1 {val_f1:.3f} | lr {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    if val_f1 > best_val_f1_improve:\n",
        "        best_val_f1_improve = val_f1\n",
        "        torch.save(model.state_dict(), best_path_improve)\n",
        "\n",
        "print(\"Improvement done ✅ Best val macro-F1:\", best_val_f1_improve)\n",
        "print(\"Improved checkpoint:\", best_path_improve)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NoAJs3LrPy-",
        "outputId": "ee54dbc3-8b31-4f76-bb94-1e88df44a9d1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improve 01/5 | train loss 0.5961 acc 0.750 f1 0.747 || val loss 1.0143 acc 0.575 f1 0.602 | lr 1.00e-04\n",
            "Improve 02/5 | train loss 0.5915 acc 0.749 f1 0.749 || val loss 0.9565 acc 0.582 f1 0.597 | lr 1.00e-04\n",
            "Improve 03/5 | train loss 0.5341 acc 0.781 f1 0.777 || val loss 0.9481 acc 0.608 f1 0.601 | lr 1.00e-04\n",
            "Improve 04/5 | train loss 0.5283 acc 0.782 f1 0.782 || val loss 1.0291 acc 0.579 f1 0.598 | lr 5.00e-05\n",
            "Improve 05/5 | train loss 0.4692 acc 0.810 f1 0.808 || val loss 0.9777 acc 0.599 f1 0.623 | lr 5.00e-05\n",
            "Improvement done ✅ Best val macro-F1: 0.6228256608717828\n",
            "Improved checkpoint: /content/experiments/densenet121_replication_20260216_173015/checkpoints/best_densenet121_improved.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- TEST evaluation (improved checkpoint) --------\n",
        "improved_model = build_densenet121(NUM_CLASSES).to(device)\n",
        "improved_model.load_state_dict(torch.load(best_path_improve, map_location=device))\n",
        "improved_model.eval()\n",
        "\n",
        "all_preds, all_targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, targets in test_loader:\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "        outputs = improved_model(imgs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy().tolist())\n",
        "        all_targets.extend(targets.cpu().numpy().tolist())\n",
        "\n",
        "test_acc = accuracy_score(all_targets, all_preds)\n",
        "test_macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "print(\"IMPROVED TEST accuracy:\", test_acc)\n",
        "print(\"IMPROVED TEST macro-F1:\", test_macro_f1)\n",
        "\n",
        "print(\"\\nClassification report (improved):\")\n",
        "print(classification_report(all_targets, all_preds, target_names=train_ds.classes, digits=4))\n",
        "\n",
        "cm = confusion_matrix(all_targets, all_preds)\n",
        "print(\"\\nConfusion matrix (improved):\\n\", cm)\n",
        "\n",
        "# save metrics\n",
        "improved_metrics = {\n",
        "    \"val_macro_f1_best_improved\": float(best_val_f1_improve),\n",
        "    \"test_accuracy_improved\": float(test_acc),\n",
        "    \"test_macro_f1_improved\": float(test_macro_f1),\n",
        "    \"improvement_note\": \"Unfroze denseblock3+4 and reduced LR to 1e-4 for 5 epochs\"\n",
        "}\n",
        "\n",
        "with open(f\"{RUN_DIR}/logs/test_metrics_improved.json\", \"w\") as f:\n",
        "    json.dump(improved_metrics, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved:\", f\"{RUN_DIR}/logs/test_metrics_improved.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8djJ8L6UsUGX",
        "outputId": "b0e931a8-671f-476d-ab82-f2ff4e2bdfc2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPROVED TEST accuracy: 0.5839371980676329\n",
            "IMPROVED TEST macro-F1: 0.597435930610521\n",
            "\n",
            "Classification report (improved):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6790    0.7449    0.7104       639\n",
            "           1     0.2872    0.3716    0.3240       296\n",
            "           2     0.6207    0.4430    0.5170       447\n",
            "           3     0.7087    0.6547    0.6807       223\n",
            "           4     0.7872    0.7255    0.7551        51\n",
            "\n",
            "    accuracy                         0.5839      1656\n",
            "   macro avg     0.6166    0.5879    0.5974      1656\n",
            "weighted avg     0.6006    0.5839    0.5865      1656\n",
            "\n",
            "\n",
            "Confusion matrix (improved):\n",
            " [[476 134  28   1   0]\n",
            " [136 110  46   4   0]\n",
            " [ 87 120 198  42   0]\n",
            " [  2  19  46 146  10]\n",
            " [  0   0   1  13  37]]\n",
            "\n",
            "Saved: /content/experiments/densenet121_replication_20260216_173015/logs/test_metrics_improved.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DenseNet121 Improvement Experiment: Higher Resolution (320)\n",
        "\n",
        "# ============================================================\n",
        "\n",
        "import os, json, time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# ---------- Config ----------\n",
        "IMAGE_SIZE = 320\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS_STAGE1 = 2     # classifier only\n",
        "EPOCHS_STAGE2 = 10    # fine-tune denseblock3+4\n",
        "LR_STAGE1 = 1e-3\n",
        "LR_STAGE2 = 1e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "# Make a separate run folder inside your existing RUN_DIR\n",
        "RUN320_DIR = os.path.join(RUN_DIR, f\"res320_{time.strftime('%H%M%S')}\")\n",
        "os.makedirs(os.path.join(RUN320_DIR, \"checkpoints\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(RUN320_DIR, \"logs\"), exist_ok=True)\n",
        "print(\"RUN320_DIR:\", RUN320_DIR)\n",
        "\n",
        "# ---------- Transforms ----------\n",
        "train_tfms_320 = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_tfms_320 = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ---------- Datasets ----------\n",
        "train_ds_320 = datasets.ImageFolder(TRAIN_DIR, transform=train_tfms_320)\n",
        "val_ds_320   = datasets.ImageFolder(VAL_DIR,   transform=val_tfms_320)\n",
        "test_ds_320  = datasets.ImageFolder(TEST_DIR,  transform=val_tfms_320)\n",
        "\n",
        "NUM_CLASSES_320 = len(train_ds_320.classes)\n",
        "print(\"Classes:\", train_ds_320.classes)\n",
        "\n",
        "# ---------- Weighted sampler ----------\n",
        "labels = np.array([y for _, y in train_ds_320.samples])\n",
        "class_counts = np.bincount(labels, minlength=NUM_CLASSES_320)\n",
        "class_weights = 1.0 / (class_counts + 1e-6)\n",
        "sample_weights = torch.DoubleTensor(class_weights[labels])\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_loader_320 = DataLoader(train_ds_320, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "val_loader_320   = DataLoader(val_ds_320,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader_320  = DataLoader(test_ds_320,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"Train class counts:\", class_counts)\n",
        "print(\"Image size:\", IMAGE_SIZE, \"Batch size:\", BATCH_SIZE)\n",
        "\n",
        "# ---------- Model ----------\n",
        "model_320 = build_densenet121(NUM_CLASSES_320).to(device)\n",
        "\n",
        "# Freeze backbone, train classifier first\n",
        "for p in model_320.parameters():\n",
        "    p.requires_grad = False\n",
        "for p in model_320.classifier.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "criterion_320 = nn.CrossEntropyLoss()\n",
        "\n",
        "def run_epoch_local(model, loader, optimizer=None):\n",
        "    train = optimizer is not None\n",
        "    model.train() if train else model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    all_preds, all_targets = [], []\n",
        "\n",
        "    for imgs, targets in loader:\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(train):\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion_320(outputs, targets)\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        all_preds.extend(preds.detach().cpu().numpy().tolist())\n",
        "        all_targets.extend(targets.detach().cpu().numpy().tolist())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "    return avg_loss, acc, macro_f1\n",
        "\n",
        "# ---------- Stage 1 ----------\n",
        "optimizer = optim.Adam(model_320.classifier.parameters(), lr=LR_STAGE1, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
        "\n",
        "best_val_f1 = -1.0\n",
        "best_path = os.path.join(RUN320_DIR, \"checkpoints\", \"best_densenet121_res320.pth\")\n",
        "\n",
        "print(f\"\\nTraining plan: {EPOCHS_STAGE1 + EPOCHS_STAGE2} epochs ({EPOCHS_STAGE1} head + {EPOCHS_STAGE2} finetune)\")\n",
        "\n",
        "for epoch in range(1, EPOCHS_STAGE1 + 1):\n",
        "    tr_loss, tr_acc, tr_f1 = run_epoch_local(model_320, train_loader_320, optimizer=optimizer)\n",
        "    va_loss, va_acc, va_f1 = run_epoch_local(model_320, val_loader_320, optimizer=None)\n",
        "    scheduler.step(va_f1)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} [head] | train loss {tr_loss:.4f} acc {tr_acc:.3f} f1 {tr_f1:.3f} || \"\n",
        "          f\"val loss {va_loss:.4f} acc {va_acc:.3f} f1 {va_f1:.3f} | lr {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    if va_f1 > best_val_f1:\n",
        "        best_val_f1 = va_f1\n",
        "        torch.save(model_320.state_dict(), best_path)\n",
        "\n",
        "# ---------- Stage 2: fine-tune denseblock3+4 ----------\n",
        "for name, param in model_320.named_parameters():\n",
        "    param.requires_grad = (\n",
        "        name.startswith(\"features.denseblock3\") or\n",
        "        name.startswith(\"features.denseblock4\") or\n",
        "        name.startswith(\"features.norm5\") or\n",
        "        name.startswith(\"classifier\")\n",
        "    )\n",
        "\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_320.parameters()),\n",
        "                       lr=LR_STAGE2, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
        "\n",
        "start_epoch = EPOCHS_STAGE1 + 1\n",
        "end_epoch = EPOCHS_STAGE1 + EPOCHS_STAGE2\n",
        "\n",
        "for epoch in range(start_epoch, end_epoch + 1):\n",
        "    tr_loss, tr_acc, tr_f1 = run_epoch_local(model_320, train_loader_320, optimizer=optimizer)\n",
        "    va_loss, va_acc, va_f1 = run_epoch_local(model_320, val_loader_320, optimizer=None)\n",
        "    scheduler.step(va_f1)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} [ft ] | train loss {tr_loss:.4f} acc {tr_acc:.3f} f1 {tr_f1:.3f} || \"\n",
        "          f\"val loss {va_loss:.4f} acc {va_acc:.3f} f1 {va_f1:.3f} | lr {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    if va_f1 > best_val_f1:\n",
        "        best_val_f1 = va_f1\n",
        "        torch.save(model_320.state_dict(), best_path)\n",
        "\n",
        "print(\"\\nBest val macro-F1 (res320):\", best_val_f1)\n",
        "print(\"Best checkpoint:\", best_path)\n",
        "\n",
        "# ---------- TEST evaluation ----------\n",
        "best_model = build_densenet121(NUM_CLASSES_320).to(device)\n",
        "best_model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "all_preds, all_targets = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, targets in test_loader_320:\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "        outputs = best_model(imgs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy().tolist())\n",
        "        all_targets.extend(targets.cpu().numpy().tolist())\n",
        "\n",
        "test_acc = accuracy_score(all_targets, all_preds)\n",
        "test_macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "print(\"\\nRES320 TEST accuracy:\", test_acc)\n",
        "print(\"RES320 TEST macro-F1:\", test_macro_f1)\n",
        "\n",
        "print(\"\\nClassification report (res320):\")\n",
        "print(classification_report(all_targets, all_preds, target_names=train_ds_320.classes, digits=4))\n",
        "\n",
        "cm = confusion_matrix(all_targets, all_preds)\n",
        "print(\"\\nConfusion matrix (res320):\\n\", cm)\n",
        "\n",
        "metrics = {\n",
        "    \"image_size\": IMAGE_SIZE,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"epochs_stage1\": EPOCHS_STAGE1,\n",
        "    \"epochs_stage2\": EPOCHS_STAGE2,\n",
        "    \"lr_stage1\": LR_STAGE1,\n",
        "    \"lr_stage2\": LR_STAGE2,\n",
        "    \"best_val_macro_f1\": float(best_val_f1),\n",
        "    \"test_accuracy\": float(test_acc),\n",
        "    \"test_macro_f1\": float(test_macro_f1),\n",
        "}\n",
        "with open(os.path.join(RUN320_DIR, \"logs\", \"metrics_res320.json\"), \"w\") as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved metrics:\", os.path.join(RUN320_DIR, \"logs\", \"metrics_res320.json\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IssXzb_27gtX",
        "outputId": "d40bc872-f7a2-40cb-d93a-7b8ffb962d20"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN320_DIR: /content/experiments/densenet121_replication_20260216_173015/res320_175510\n",
            "Classes: ['0', '1', '2', '3', '4']\n",
            "Train class counts: [2286 1046 1516  757  173]\n",
            "Image size: 320 Batch size: 16\n",
            "\n",
            "Training plan: 12 epochs (2 head + 10 finetune)\n",
            "Epoch 01 [head] | train loss 1.5589 acc 0.293 f1 0.288 || val loss 1.4107 acc 0.406 f1 0.270 | lr 1.00e-03\n",
            "Epoch 02 [head] | train loss 1.4527 acc 0.350 f1 0.345 || val loss 1.4532 acc 0.407 f1 0.274 | lr 1.00e-03\n",
            "Epoch 03 [ft ] | train loss 0.9798 acc 0.573 f1 0.568 || val loss 1.1018 acc 0.435 f1 0.526 | lr 1.00e-04\n",
            "Epoch 04 [ft ] | train loss 0.7847 acc 0.656 f1 0.658 || val loss 0.9263 acc 0.592 f1 0.610 | lr 1.00e-04\n",
            "Epoch 05 [ft ] | train loss 0.7124 acc 0.693 f1 0.690 || val loss 0.9128 acc 0.585 f1 0.601 | lr 1.00e-04\n",
            "Epoch 06 [ft ] | train loss 0.6727 acc 0.702 f1 0.696 || val loss 0.8529 acc 0.653 f1 0.638 | lr 1.00e-04\n",
            "Epoch 07 [ft ] | train loss 0.6540 acc 0.719 f1 0.717 || val loss 0.9504 acc 0.592 f1 0.630 | lr 1.00e-04\n",
            "Epoch 08 [ft ] | train loss 0.6108 acc 0.734 f1 0.734 || val loss 0.9843 acc 0.529 f1 0.615 | lr 1.00e-04\n",
            "Epoch 09 [ft ] | train loss 0.5879 acc 0.752 f1 0.749 || val loss 0.8643 acc 0.596 f1 0.639 | lr 1.00e-04\n",
            "Epoch 10 [ft ] | train loss 0.5644 acc 0.760 f1 0.755 || val loss 0.9333 acc 0.567 f1 0.634 | lr 1.00e-04\n",
            "Epoch 11 [ft ] | train loss 0.5465 acc 0.769 f1 0.770 || val loss 0.8924 acc 0.617 f1 0.644 | lr 1.00e-04\n",
            "Epoch 12 [ft ] | train loss 0.5207 acc 0.782 f1 0.781 || val loss 0.8773 acc 0.636 f1 0.632 | lr 1.00e-04\n",
            "\n",
            "Best val macro-F1 (res320): 0.6435457338473395\n",
            "Best checkpoint: /content/experiments/densenet121_replication_20260216_173015/res320_175510/checkpoints/best_densenet121_res320.pth\n",
            "\n",
            "RES320 TEST accuracy: 0.6491545893719807\n",
            "RES320 TEST macro-F1: 0.6483853377692689\n",
            "\n",
            "Classification report (res320):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7623    0.7527    0.7575       639\n",
            "           1     0.3207    0.2568    0.2852       296\n",
            "           2     0.6008    0.6935    0.6438       447\n",
            "           3     0.7639    0.7399    0.7517       223\n",
            "           4     0.7679    0.8431    0.8037        51\n",
            "\n",
            "    accuracy                         0.6492      1656\n",
            "   macro avg     0.6431    0.6572    0.6484      1656\n",
            "weighted avg     0.6401    0.6492    0.6430      1656\n",
            "\n",
            "\n",
            "Confusion matrix (res320):\n",
            " [[481  99  57   2   0]\n",
            " [109  76 107   4   0]\n",
            " [ 41  58 310  38   0]\n",
            " [  0   4  41 165  13]\n",
            " [  0   0   1   7  43]]\n",
            "\n",
            "Saved metrics: /content/experiments/densenet121_replication_20260216_173015/res320_175510/logs/metrics_res320.json\n"
          ]
        }
      ]
    }
  ]
}