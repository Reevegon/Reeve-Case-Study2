{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzETZmxki_hB",
        "outputId": "43ae0ff1-b08e-4eb8-9dc1-1f79f97d1d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset not found. Mounting Drive...\n",
            "Mounted at /content/drive\n",
            "Unzipping dataset...\n",
            "Dataset ready ✅\n",
            "['.config', 'drive', 'knee-osteoarthritis-dataset-with-severity', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# AUTO DATASET LOADER + DenseNet121 Replication\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "\n",
        "DATASET_NAME = \"knee-osteoarthritis-dataset-with-severity\"\n",
        "ZIP_NAME = \"knee_oa_dataset.zip\"   # make sure this matches your Drive\n",
        "\n",
        "if not os.path.isdir(f\"/content/{DATASET_NAME}\"):\n",
        "    print(\"Dataset not found. Mounting Drive...\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    zip_path = f\"/content/drive/MyDrive/{ZIP_NAME}\"\n",
        "    if not os.path.isfile(zip_path):\n",
        "        raise FileNotFoundError(f\"ZIP file not found at {zip_path}\")\n",
        "\n",
        "    print(\"Unzipping dataset...\")\n",
        "    !unzip -q \"{zip_path}\" -d /content/\n",
        "\n",
        "print(\"Dataset ready ✅\")\n",
        "print(os.listdir(\"/content\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, time, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULyBZwXpj1NP",
        "outputId": "b9570488-879c-4faf-e976-1bca7c3b7bc9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/knee-osteoarthritis-dataset-with-severity\"\n",
        "TRAIN_DIR = f\"{DATA_DIR}/train\"\n",
        "VAL_DIR   = f\"{DATA_DIR}/val\"\n",
        "TEST_DIR  = f\"{DATA_DIR}/test\"\n",
        "\n",
        "RUN_NAME = time.strftime(\"densenet121_replication_%Y%m%d_%H%M%S\")\n",
        "RUN_DIR = f\"/content/experiments/{RUN_NAME}\"\n",
        "os.makedirs(f\"{RUN_DIR}/checkpoints\", exist_ok=True)\n",
        "os.makedirs(f\"{RUN_DIR}/logs\", exist_ok=True)\n",
        "\n",
        "print(\"RUN_DIR:\", RUN_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayamFhfIj4RA",
        "outputId": "16de3ae0-9041-4b64-9830-29274cc3c43a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN_DIR: /content/experiments/densenet121_replication_20260213_165424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "6JwgRyaZj60Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(VAL_DIR, transform=val_tfms)\n",
        "test_ds  = datasets.ImageFolder(TEST_DIR, transform=val_tfms)\n",
        "\n",
        "NUM_CLASSES = len(train_ds.classes)\n",
        "print(\"Classes:\", train_ds.classes)\n",
        "\n",
        "# Weighted sampler (replicating imbalance handling from literature)\n",
        "labels = np.array([y for _, y in train_ds.samples])\n",
        "class_counts = np.bincount(labels, minlength=NUM_CLASSES)\n",
        "class_weights = 1.0 / (class_counts + 1e-6)\n",
        "sample_weights = torch.DoubleTensor(class_weights[labels])\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"Train class counts:\", class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfNc9pCQj9pM",
        "outputId": "68f6ef3f-ea45-48f2-ccdd-c0045d84e046"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['0', '1', '2', '3', '4']\n",
            "Train class counts: [2286 1046 1516  757  173]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_densenet121(num_classes):\n",
        "    model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
        "    in_features = model.classifier.in_features\n",
        "    model.classifier = nn.Linear(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "model = build_densenet121(NUM_CLASSES).to(device)\n",
        "\n",
        "# Freeze backbone first\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\"DenseNet121 ready ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WOJf3W_j_7v",
        "outputId": "62056a80-6867-4454-ae8a-0acceea16d90"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 190MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DenseNet121 ready ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss (standard CE for replication baseline)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(\"Using CrossEntropyLoss ✅\")\n",
        "\n",
        "# Stage 1: train only classifier\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode=\"max\",\n",
        "    factor=0.5,\n",
        "    patience=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahpuq3OQkivq",
        "outputId": "b994c79c-9a60-487a-ef2f-69457b67aa64"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CrossEntropyLoss ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(model, loader, train=False):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    all_preds, all_targets = [], []\n",
        "\n",
        "    for imgs, targets in loader:\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(train):\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        all_preds.extend(preds.detach().cpu().numpy())\n",
        "        all_targets.extend(targets.detach().cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "    return avg_loss, acc, macro_f1"
      ],
      "metadata": {
        "id": "PCM8QF3TksXT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = []\n",
        "best_val_f1 = 0\n",
        "best_path = f\"{RUN_DIR}/checkpoints/best_densenet121.pth\"\n",
        "\n",
        "EPOCHS_STAGE1 = 3\n",
        "EPOCHS_STAGE2 = 17\n",
        "TOTAL_EPOCHS = EPOCHS_STAGE1 + EPOCHS_STAGE2\n",
        "\n",
        "print(\"Training plan:\", TOTAL_EPOCHS, \"epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS_STAGE1 + 1):\n",
        "\n",
        "    train_loss, train_acc, train_f1 = run_epoch(model, train_loader, train=True)\n",
        "    val_loss, val_acc, val_f1 = run_epoch(model, val_loader, train=False)\n",
        "\n",
        "    scheduler.step(val_f1)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"train loss {train_loss:.4f} acc {train_acc:.3f} f1 {train_f1:.3f} || \"\n",
        "          f\"val loss {val_loss:.4f} acc {val_acc:.3f} f1 {val_f1:.3f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), best_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "wsIfgIr8kvG5",
        "outputId": "1ce2cee4-0185-4eef-e7cc-aca57030597c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training plan: 20 epochs\n",
            "Epoch 01 | train loss 1.5281 acc 0.305 f1 0.297 || val loss 1.4398 acc 0.317 f1 0.263\n",
            "Epoch 02 | train loss 1.3959 acc 0.375 f1 0.362 || val loss 1.3792 acc 0.361 f1 0.328\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3587780755.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS_STAGE1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3856721096.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, loader, train)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Stage 2: fine-tune last dense block + classifier --------\n",
        "\n",
        "# Unfreeze only: features.denseblock4 + features.norm5 + classifier\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = (\n",
        "        name.startswith(\"features.denseblock4\") or\n",
        "        name.startswith(\"features.norm5\") or\n",
        "        name.startswith(\"classifier\")\n",
        "    )\n",
        "\n",
        "# New optimizer for fine-tuning (smaller LR)\n",
        "optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=3e-4,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"max\", factor=0.5, patience=2\n",
        ")\n",
        "\n",
        "start_epoch = EPOCHS_STAGE1 + 1\n",
        "\n",
        "for epoch in range(start_epoch, TOTAL_EPOCHS + 1):\n",
        "    train_loss, train_acc, train_f1 = run_epoch(model, train_loader, train=True)\n",
        "    val_loss, val_acc, val_f1 = run_epoch(model, val_loader, train=False)\n",
        "\n",
        "    scheduler.step(val_f1)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"train loss {train_loss:.4f} acc {train_acc:.3f} f1 {train_f1:.3f} || \"\n",
        "          f\"val loss {val_loss:.4f} acc {val_acc:.3f} f1 {val_f1:.3f} | lr {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "\n",
        "print(\"Stage2 done ✅ Best val macro-F1:\", best_val_f1)\n",
        "print(\"Best checkpoint:\", best_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSfSbVKjmQw3",
        "outputId": "285a6453-3e65-42a1-a41f-48e45c8b98a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 | train loss 0.5994 acc 0.738 f1 0.736 || val loss 1.1373 acc 0.523 f1 0.594 | lr 3.00e-04\n",
            "Epoch 05 | train loss 0.5966 acc 0.743 f1 0.741 || val loss 1.1038 acc 0.518 f1 0.572 | lr 3.00e-04\n",
            "Epoch 06 | train loss 0.5874 acc 0.754 f1 0.752 || val loss 1.1189 acc 0.517 f1 0.584 | lr 3.00e-04\n",
            "Epoch 07 | train loss 0.5650 acc 0.764 f1 0.765 || val loss 1.0977 acc 0.535 f1 0.602 | lr 3.00e-04\n",
            "Epoch 08 | train loss 0.5595 acc 0.760 f1 0.761 || val loss 1.1507 acc 0.542 f1 0.586 | lr 3.00e-04\n",
            "Epoch 09 | train loss 0.5537 acc 0.758 f1 0.759 || val loss 1.1791 acc 0.551 f1 0.553 | lr 3.00e-04\n",
            "Epoch 10 | train loss 0.5598 acc 0.768 f1 0.765 || val loss 1.0737 acc 0.563 f1 0.564 | lr 1.50e-04\n",
            "Epoch 11 | train loss 0.5002 acc 0.787 f1 0.786 || val loss 1.0742 acc 0.569 f1 0.603 | lr 1.50e-04\n",
            "Epoch 12 | train loss 0.4787 acc 0.807 f1 0.806 || val loss 1.1422 acc 0.544 f1 0.586 | lr 1.50e-04\n",
            "Epoch 13 | train loss 0.4543 acc 0.811 f1 0.812 || val loss 1.1454 acc 0.563 f1 0.583 | lr 1.50e-04\n",
            "Epoch 14 | train loss 0.4545 acc 0.810 f1 0.811 || val loss 1.1914 acc 0.539 f1 0.577 | lr 7.50e-05\n",
            "Epoch 15 | train loss 0.4248 acc 0.826 f1 0.826 || val loss 1.1223 acc 0.582 f1 0.608 | lr 7.50e-05\n",
            "Epoch 16 | train loss 0.4162 acc 0.832 f1 0.833 || val loss 1.1597 acc 0.563 f1 0.596 | lr 7.50e-05\n",
            "Epoch 17 | train loss 0.4078 acc 0.837 f1 0.838 || val loss 1.1251 acc 0.592 f1 0.614 | lr 7.50e-05\n",
            "Epoch 18 | train loss 0.4023 acc 0.839 f1 0.838 || val loss 1.1595 acc 0.579 f1 0.616 | lr 7.50e-05\n",
            "Epoch 19 | train loss 0.3792 acc 0.852 f1 0.852 || val loss 1.1266 acc 0.576 f1 0.592 | lr 7.50e-05\n",
            "Epoch 20 | train loss 0.3787 acc 0.840 f1 0.838 || val loss 1.1750 acc 0.569 f1 0.597 | lr 7.50e-05\n",
            "Stage2 done ✅ Best val macro-F1: 0.616339366579932\n",
            "Best checkpoint: /content/experiments/densenet121_replication_20260211_211601/checkpoints/best_densenet121.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- TEST evaluation (best checkpoint) --------\n",
        "best_model = build_densenet121(NUM_CLASSES).to(device)\n",
        "best_model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "all_preds, all_targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, targets in test_loader:\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "        outputs = best_model(imgs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy().tolist())\n",
        "        all_targets.extend(targets.cpu().numpy().tolist())\n",
        "\n",
        "test_acc = accuracy_score(all_targets, all_preds)\n",
        "test_macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "print(\"TEST accuracy:\", test_acc)\n",
        "print(\"TEST macro-F1:\", test_macro_f1)\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(all_targets, all_preds, target_names=train_ds.classes, digits=4))\n",
        "\n",
        "cm = confusion_matrix(all_targets, all_preds)\n",
        "print(\"\\nConfusion matrix:\\n\", cm)\n",
        "\n",
        "# save metrics for your report\n",
        "metrics = {\n",
        "    \"best_val_macro_f1\": float(best_val_f1),\n",
        "    \"test_accuracy\": float(test_acc),\n",
        "    \"test_macro_f1\": float(test_macro_f1),\n",
        "    \"epochs_stage1\": EPOCHS_STAGE1,\n",
        "    \"epochs_stage2\": EPOCHS_STAGE2,\n",
        "    \"image_size\": IMAGE_SIZE,\n",
        "    \"batch_size\": BATCH_SIZE\n",
        "}\n",
        "\n",
        "with open(f\"{RUN_DIR}/logs/test_metrics.json\", \"w\") as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved:\", f\"{RUN_DIR}/logs/test_metrics.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8Ezvaizqwwt",
        "outputId": "5655ab25-e155-4d54-f62f-20e0808827f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST accuracy: 0.5597826086956522\n",
            "TEST macro-F1: 0.5859640582408333\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7135    0.6275    0.6678       639\n",
            "           1     0.2747    0.3480    0.3070       296\n",
            "           2     0.5269    0.5705    0.5478       447\n",
            "           3     0.6995    0.5740    0.6305       223\n",
            "           4     0.7692    0.7843    0.7767        51\n",
            "\n",
            "    accuracy                         0.5598      1656\n",
            "   macro avg     0.5967    0.5809    0.5860      1656\n",
            "weighted avg     0.5845    0.5598    0.5692      1656\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[401 165  72   1   0]\n",
            " [ 95 103  91   7   0]\n",
            " [ 62  92 255  37   1]\n",
            " [  4  15  65 128  11]\n",
            " [  0   0   1  10  40]]\n",
            "\n",
            "Saved: /content/experiments/densenet121_replication_20260211_211601/logs/test_metrics.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Improvement Experiment: deeper fine-tuning ----------\n",
        "# Load best checkpoint first (start from best weights)\n",
        "model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "\n",
        "# Unfreeze denseblock3 + denseblock4 + norm layers + classifier\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = (\n",
        "        name.startswith(\"features.denseblock3\") or\n",
        "        name.startswith(\"features.denseblock4\") or\n",
        "        name.startswith(\"features.norm5\") or\n",
        "        name.startswith(\"classifier\")\n",
        "    )\n",
        "\n",
        "# Lower LR for stability\n",
        "optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-4,           # LOWER than before\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"max\", factor=0.5, patience=2\n",
        ")\n",
        "\n",
        "# Run a short improvement fine-tune (5 epochs)\n",
        "IMPROVE_EPOCHS = 5\n",
        "best_val_f1_improve = best_val_f1\n",
        "best_path_improve = f\"{RUN_DIR}/checkpoints/best_densenet121_improved.pth\"\n",
        "\n",
        "for e in range(1, IMPROVE_EPOCHS + 1):\n",
        "    train_loss, train_acc, train_f1 = run_epoch(model, train_loader, train=True)\n",
        "    val_loss, val_acc, val_f1 = run_epoch(model, val_loader, train=False)\n",
        "\n",
        "    scheduler.step(val_f1)\n",
        "\n",
        "    print(f\"Improve {e:02d}/{IMPROVE_EPOCHS} | \"\n",
        "          f\"train loss {train_loss:.4f} acc {train_acc:.3f} f1 {train_f1:.3f} || \"\n",
        "          f\"val loss {val_loss:.4f} acc {val_acc:.3f} f1 {val_f1:.3f} | lr {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    if val_f1 > best_val_f1_improve:\n",
        "        best_val_f1_improve = val_f1\n",
        "        torch.save(model.state_dict(), best_path_improve)\n",
        "\n",
        "print(\"Improvement done ✅ Best val macro-F1:\", best_val_f1_improve)\n",
        "print(\"Improved checkpoint:\", best_path_improve)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NoAJs3LrPy-",
        "outputId": "8ce5d89e-6de6-433d-ad19-13f787678c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improve 01/5 | train loss 0.4464 acc 0.813 f1 0.814 || val loss 1.2226 acc 0.567 f1 0.595 | lr 1.00e-04\n",
            "Improve 02/5 | train loss 0.4478 acc 0.819 f1 0.819 || val loss 1.1799 acc 0.561 f1 0.607 | lr 1.00e-04\n",
            "Improve 03/5 | train loss 0.4064 acc 0.835 f1 0.834 || val loss 1.1209 acc 0.577 f1 0.580 | lr 1.00e-04\n",
            "Improve 04/5 | train loss 0.3994 acc 0.841 f1 0.842 || val loss 1.1143 acc 0.616 f1 0.632 | lr 1.00e-04\n",
            "Improve 05/5 | train loss 0.3817 acc 0.851 f1 0.851 || val loss 1.2131 acc 0.590 f1 0.599 | lr 1.00e-04\n",
            "Improvement done ✅ Best val macro-F1: 0.6322343369433788\n",
            "Improved checkpoint: /content/experiments/densenet121_replication_20260211_211601/checkpoints/best_densenet121_improved.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- TEST evaluation (improved checkpoint) --------\n",
        "improved_model = build_densenet121(NUM_CLASSES).to(device)\n",
        "improved_model.load_state_dict(torch.load(best_path_improve, map_location=device))\n",
        "improved_model.eval()\n",
        "\n",
        "all_preds, all_targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, targets in test_loader:\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "        outputs = improved_model(imgs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy().tolist())\n",
        "        all_targets.extend(targets.cpu().numpy().tolist())\n",
        "\n",
        "test_acc = accuracy_score(all_targets, all_preds)\n",
        "test_macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "print(\"IMPROVED TEST accuracy:\", test_acc)\n",
        "print(\"IMPROVED TEST macro-F1:\", test_macro_f1)\n",
        "\n",
        "print(\"\\nClassification report (improved):\")\n",
        "print(classification_report(all_targets, all_preds, target_names=train_ds.classes, digits=4))\n",
        "\n",
        "cm = confusion_matrix(all_targets, all_preds)\n",
        "print(\"\\nConfusion matrix (improved):\\n\", cm)\n",
        "\n",
        "# save metrics\n",
        "improved_metrics = {\n",
        "    \"val_macro_f1_best_improved\": float(best_val_f1_improve),\n",
        "    \"test_accuracy_improved\": float(test_acc),\n",
        "    \"test_macro_f1_improved\": float(test_macro_f1),\n",
        "    \"improvement_note\": \"Unfroze denseblock3+4 and reduced LR to 1e-4 for 5 epochs\"\n",
        "}\n",
        "\n",
        "with open(f\"{RUN_DIR}/logs/test_metrics_improved.json\", \"w\") as f:\n",
        "    json.dump(improved_metrics, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved:\", f\"{RUN_DIR}/logs/test_metrics_improved.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8djJ8L6UsUGX",
        "outputId": "7c430eac-56c7-4f48-af94-d991414a165b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPROVED TEST accuracy: 0.586352657004831\n",
            "IMPROVED TEST macro-F1: 0.5804526179580181\n",
            "\n",
            "Classification report (improved):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7141    0.6917    0.7027       639\n",
            "           1     0.3333    0.2297    0.2720       296\n",
            "           2     0.5077    0.6622    0.5748       447\n",
            "           3     0.6410    0.5605    0.5981       223\n",
            "           4     0.7273    0.7843    0.7547        51\n",
            "\n",
            "    accuracy                         0.5864      1656\n",
            "   macro avg     0.5847    0.5857    0.5805      1656\n",
            "weighted avg     0.5809    0.5864    0.5787      1656\n",
            "\n",
            "\n",
            "Confusion matrix (improved):\n",
            " [[442  89 104   4   0]\n",
            " [104  68 111  13   0]\n",
            " [ 68  40 296  43   0]\n",
            " [  5   7  71 125  15]\n",
            " [  0   0   1  10  40]]\n",
            "\n",
            "Saved: /content/experiments/densenet121_replication_20260211_211601/logs/test_metrics_improved.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DenseNet121 Improvement Experiment: Higher Resolution (320)\n",
        "\n",
        "# ============================================================\n",
        "\n",
        "import os, json, time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# ---------- Config ----------\n",
        "IMAGE_SIZE = 320\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS_STAGE1 = 2     # classifier only\n",
        "EPOCHS_STAGE2 = 10    # fine-tune denseblock3+4\n",
        "LR_STAGE1 = 1e-3\n",
        "LR_STAGE2 = 1e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "# Make a separate run folder inside your existing RUN_DIR\n",
        "RUN320_DIR = os.path.join(RUN_DIR, f\"res320_{time.strftime('%H%M%S')}\")\n",
        "os.makedirs(os.path.join(RUN320_DIR, \"checkpoints\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(RUN320_DIR, \"logs\"), exist_ok=True)\n",
        "print(\"RUN320_DIR:\", RUN320_DIR)\n",
        "\n",
        "# ---------- Transforms ----------\n",
        "train_tfms_320 = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_tfms_320 = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ---------- Datasets ----------\n",
        "train_ds_320 = datasets.ImageFolder(TRAIN_DIR, transform=train_tfms_320)\n",
        "val_ds_320   = datasets.ImageFolder(VAL_DIR,   transform=val_tfms_320)\n",
        "test_ds_320  = datasets.ImageFolder(TEST_DIR,  transform=val_tfms_320)\n",
        "\n",
        "NUM_CLASSES_320 = len(train_ds_320.classes)\n",
        "print(\"Classes:\", train_ds_320.classes)\n",
        "\n",
        "# ---------- Weighted sampler ----------\n",
        "labels = np.array([y for _, y in train_ds_320.samples])\n",
        "class_counts = np.bincount(labels, minlength=NUM_CLASSES_320)\n",
        "class_weights = 1.0 / (class_counts + 1e-6)\n",
        "sample_weights = torch.DoubleTensor(class_weights[labels])\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_loader_320 = DataLoader(train_ds_320, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "val_loader_320   = DataLoader(val_ds_320,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader_320  = DataLoader(test_ds_320,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"Train class counts:\", class_counts)\n",
        "print(\"Image size:\", IMAGE_SIZE, \"Batch size:\", BATCH_SIZE)\n",
        "\n",
        "# ---------- Model ----------\n",
        "model_320 = build_densenet121(NUM_CLASSES_320).to(device)\n",
        "\n",
        "# Freeze backbone, train classifier first\n",
        "for p in model_320.parameters():\n",
        "    p.requires_grad = False\n",
        "for p in model_320.classifier.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "criterion_320 = nn.CrossEntropyLoss()\n",
        "\n",
        "def run_epoch_local(model, loader, optimizer=None):\n",
        "    train = optimizer is not None\n",
        "    model.train() if train else model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    all_preds, all_targets = [], []\n",
        "\n",
        "    for imgs, targets in loader:\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(train):\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion_320(outputs, targets)\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        all_preds.extend(preds.detach().cpu().numpy().tolist())\n",
        "        all_targets.extend(targets.detach().cpu().numpy().tolist())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "    return avg_loss, acc, macro_f1\n",
        "\n",
        "# ---------- Stage 1 ----------\n",
        "optimizer = optim.Adam(model_320.classifier.parameters(), lr=LR_STAGE1, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
        "\n",
        "best_val_f1 = -1.0\n",
        "best_path = os.path.join(RUN320_DIR, \"checkpoints\", \"best_densenet121_res320.pth\")\n",
        "\n",
        "print(f\"\\nTraining plan: {EPOCHS_STAGE1 + EPOCHS_STAGE2} epochs ({EPOCHS_STAGE1} head + {EPOCHS_STAGE2} finetune)\")\n",
        "\n",
        "for epoch in range(1, EPOCHS_STAGE1 + 1):\n",
        "    tr_loss, tr_acc, tr_f1 = run_epoch_local(model_320, train_loader_320, optimizer=optimizer)\n",
        "    va_loss, va_acc, va_f1 = run_epoch_local(model_320, val_loader_320, optimizer=None)\n",
        "    scheduler.step(va_f1)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} [head] | train loss {tr_loss:.4f} acc {tr_acc:.3f} f1 {tr_f1:.3f} || \"\n",
        "          f\"val loss {va_loss:.4f} acc {va_acc:.3f} f1 {va_f1:.3f} | lr {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    if va_f1 > best_val_f1:\n",
        "        best_val_f1 = va_f1\n",
        "        torch.save(model_320.state_dict(), best_path)\n",
        "\n",
        "# ---------- Stage 2: fine-tune denseblock3+4 ----------\n",
        "for name, param in model_320.named_parameters():\n",
        "    param.requires_grad = (\n",
        "        name.startswith(\"features.denseblock3\") or\n",
        "        name.startswith(\"features.denseblock4\") or\n",
        "        name.startswith(\"features.norm5\") or\n",
        "        name.startswith(\"classifier\")\n",
        "    )\n",
        "\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_320.parameters()),\n",
        "                       lr=LR_STAGE2, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
        "\n",
        "start_epoch = EPOCHS_STAGE1 + 1\n",
        "end_epoch = EPOCHS_STAGE1 + EPOCHS_STAGE2\n",
        "\n",
        "for epoch in range(start_epoch, end_epoch + 1):\n",
        "    tr_loss, tr_acc, tr_f1 = run_epoch_local(model_320, train_loader_320, optimizer=optimizer)\n",
        "    va_loss, va_acc, va_f1 = run_epoch_local(model_320, val_loader_320, optimizer=None)\n",
        "    scheduler.step(va_f1)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} [ft ] | train loss {tr_loss:.4f} acc {tr_acc:.3f} f1 {tr_f1:.3f} || \"\n",
        "          f\"val loss {va_loss:.4f} acc {va_acc:.3f} f1 {va_f1:.3f} | lr {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    if va_f1 > best_val_f1:\n",
        "        best_val_f1 = va_f1\n",
        "        torch.save(model_320.state_dict(), best_path)\n",
        "\n",
        "print(\"\\nBest val macro-F1 (res320):\", best_val_f1)\n",
        "print(\"Best checkpoint:\", best_path)\n",
        "\n",
        "# ---------- TEST evaluation ----------\n",
        "best_model = build_densenet121(NUM_CLASSES_320).to(device)\n",
        "best_model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "all_preds, all_targets = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, targets in test_loader_320:\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "        outputs = best_model(imgs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy().tolist())\n",
        "        all_targets.extend(targets.cpu().numpy().tolist())\n",
        "\n",
        "test_acc = accuracy_score(all_targets, all_preds)\n",
        "test_macro_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "print(\"\\nRES320 TEST accuracy:\", test_acc)\n",
        "print(\"RES320 TEST macro-F1:\", test_macro_f1)\n",
        "\n",
        "print(\"\\nClassification report (res320):\")\n",
        "print(classification_report(all_targets, all_preds, target_names=train_ds_320.classes, digits=4))\n",
        "\n",
        "cm = confusion_matrix(all_targets, all_preds)\n",
        "print(\"\\nConfusion matrix (res320):\\n\", cm)\n",
        "\n",
        "metrics = {\n",
        "    \"image_size\": IMAGE_SIZE,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"epochs_stage1\": EPOCHS_STAGE1,\n",
        "    \"epochs_stage2\": EPOCHS_STAGE2,\n",
        "    \"lr_stage1\": LR_STAGE1,\n",
        "    \"lr_stage2\": LR_STAGE2,\n",
        "    \"best_val_macro_f1\": float(best_val_f1),\n",
        "    \"test_accuracy\": float(test_acc),\n",
        "    \"test_macro_f1\": float(test_macro_f1),\n",
        "}\n",
        "with open(os.path.join(RUN320_DIR, \"logs\", \"metrics_res320.json\"), \"w\") as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved metrics:\", os.path.join(RUN320_DIR, \"logs\", \"metrics_res320.json\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IssXzb_27gtX",
        "outputId": "e715ff12-1a89-4752-b568-03b06bf5c4f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN320_DIR: /content/experiments/densenet121_replication_20260213_165424/res320_165549\n",
            "Classes: ['0', '1', '2', '3', '4']\n",
            "Train class counts: [2286 1046 1516  757  173]\n",
            "Image size: 320 Batch size: 16\n",
            "\n",
            "Training plan: 12 epochs (2 head + 10 finetune)\n",
            "Epoch 01 [head] | train loss 1.5583 acc 0.279 f1 0.275 || val loss 1.4700 acc 0.314 f1 0.231 | lr 1.00e-03\n",
            "Epoch 02 [head] | train loss 1.4487 acc 0.357 f1 0.346 || val loss 1.3511 acc 0.419 f1 0.263 | lr 1.00e-03\n",
            "Epoch 03 [ft ] | train loss 0.9796 acc 0.569 f1 0.556 || val loss 0.9225 acc 0.604 f1 0.600 | lr 1.00e-04\n",
            "Epoch 04 [ft ] | train loss 0.7966 acc 0.651 f1 0.648 || val loss 0.8969 acc 0.600 f1 0.625 | lr 1.00e-04\n",
            "Epoch 05 [ft ] | train loss 0.7124 acc 0.682 f1 0.679 || val loss 0.9102 acc 0.600 f1 0.628 | lr 1.00e-04\n",
            "Epoch 06 [ft ] | train loss 0.6941 acc 0.694 f1 0.692 || val loss 0.8821 acc 0.603 f1 0.641 | lr 1.00e-04\n",
            "Epoch 07 [ft ] | train loss 0.6413 acc 0.721 f1 0.719 || val loss 0.8450 acc 0.633 f1 0.615 | lr 1.00e-04\n",
            "Epoch 08 [ft ] | train loss 0.6015 acc 0.744 f1 0.740 || val loss 0.8663 acc 0.628 f1 0.666 | lr 1.00e-04\n",
            "Epoch 09 [ft ] | train loss 0.5857 acc 0.753 f1 0.751 || val loss 0.9163 acc 0.591 f1 0.643 | lr 1.00e-04\n",
            "Epoch 10 [ft ] | train loss 0.5729 acc 0.753 f1 0.753 || val loss 0.9791 acc 0.613 f1 0.600 | lr 1.00e-04\n",
            "Epoch 11 [ft ] | train loss 0.5420 acc 0.769 f1 0.771 || val loss 1.0709 acc 0.541 f1 0.588 | lr 5.00e-05\n",
            "Epoch 12 [ft ] | train loss 0.4921 acc 0.799 f1 0.799 || val loss 0.9243 acc 0.633 f1 0.657 | lr 5.00e-05\n",
            "\n",
            "Best val macro-F1 (res320): 0.665976593810187\n",
            "Best checkpoint: /content/experiments/densenet121_replication_20260213_165424/res320_165549/checkpoints/best_densenet121_res320.pth\n",
            "\n",
            "RES320 TEST accuracy: 0.6455314009661836\n",
            "RES320 TEST macro-F1: 0.6541842288495628\n",
            "\n",
            "Classification report (res320):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7632    0.7465    0.7547       639\n",
            "           1     0.3256    0.2838    0.3032       296\n",
            "           2     0.5943    0.6488    0.6203       447\n",
            "           3     0.7427    0.8027    0.7716       223\n",
            "           4     0.8864    0.7647    0.8211        51\n",
            "\n",
            "    accuracy                         0.6455      1656\n",
            "   macro avg     0.6624    0.6493    0.6542      1656\n",
            "weighted avg     0.6404    0.6455    0.6421      1656\n",
            "\n",
            "\n",
            "Confusion matrix (res320):\n",
            " [[477 100  59   3   0]\n",
            " [104  84 104   4   0]\n",
            " [ 43  70 290  44   0]\n",
            " [  1   4  34 179   5]\n",
            " [  0   0   1  11  39]]\n",
            "\n",
            "Saved metrics: /content/experiments/densenet121_replication_20260213_165424/res320_165549/logs/metrics_res320.json\n"
          ]
        }
      ]
    }
  ]
}